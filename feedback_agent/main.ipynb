{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a12bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,Annotated,Sequence\n",
    "from langchain_core.messages import BaseMessage,ToolMessage,SystemMessage,HumanMessage,AIMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60b8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = Path('.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "api_key=os.getenv(\"gptAPIKEY\")\n",
    "# print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7acb9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ChatOpenAI(model=\"deepseek/deepseek-chat-v3-0324:free\",api_key=api_key,base_url=\"https://openrouter.ai/api/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a59b3765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_agent(TypedDict):\n",
    "    message : Annotated[Sequence[BaseMessage], add_messages]\n",
    "    code: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f546cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: Generator_agent) -> Generator_agent:\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    you generate the code based on the user input in python.\n",
    "    you only provide the result code and nothing else.\n",
    "    \"\"\")\n",
    "    # if state['message']=='':\n",
    "    a=HumanMessage(content= input(\"pls do some thing\"))\n",
    "    final_message=[system_prompt,a]\n",
    "    # else:\n",
    "    #     final_message=state['message']\n",
    "    print(\"i\")\n",
    "    response = model.invoke(final_message)\n",
    "    if response.content:\n",
    "        print(response.content)\n",
    "        return{'message':[response]}\n",
    "    else:\n",
    "        print(\"no response\")\n",
    "\n",
    "def process(state:Generator_agent)->Generator_agent:\n",
    "    print(\"j\")\n",
    "    res=state['message']\n",
    "    val=res[1].content\n",
    "    val=val.replace('\\n','')\n",
    "    val=val.strip('`')\n",
    "    val=val[6:]\n",
    "    return {'code':val}\n",
    "\n",
    "def evaluvate(state:Generator_agent)->Generator_agent:\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    you test the code i give you and give me feedback on my code of the form.\n",
    "    {{ \n",
    "    \"correctness\": 0 to 10,\n",
    "    \"efficiency\": 0 to 10,\n",
    "    \"style\": 0 to 10,\n",
    "    \"issues\": [any case where the procgram fails]    \n",
    "    }}\n",
    "    \"\"\")\n",
    "    print('k')\n",
    "    response = model.invoke([system_prompt+HumanMessage(content=state['code'])])\n",
    "    if response.content:\n",
    "        print(response.content)\n",
    "        return {'message',[response]}\n",
    "\n",
    "def cond(state:Generator_agent)->Generator_agent:\n",
    "    print(state['message'])\n",
    "    a=input(\"choice\")\n",
    "    if a==\"end\":\n",
    "        return \"end\"\n",
    "    return {'message':[a]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7b9c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph=StateGraph(Generator_agent)\n",
    "# graph.add_node('main',process)\n",
    "# graph.add_node('cho',lambda state:state)\n",
    "# graph.set_entry_point('main')\n",
    "# graph.add_edge('main','cho')\n",
    "# graph.add_conditional_edges(\n",
    "#     'cho',\n",
    "#     cond,\n",
    "#     {\n",
    "#         \"continue\":\"main\",\n",
    "#         \"end\":END,\n",
    "#     }\n",
    "# )\n",
    "# app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9346f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(Generator_agent)\n",
    "graph.add_node('main',generate)\n",
    "graph.add_node('process',process)\n",
    "graph.add_node('revise',evaluvate)\n",
    "\n",
    "graph.set_entry_point('main')\n",
    "graph.add_edge('main','process')\n",
    "graph.add_edge('process','revise')\n",
    "graph.set_finish_point('revise')\n",
    "\n",
    "app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a59a46d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image,display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6444b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "{'message': 'Provider returned error', 'code': 524, 'metadata': {'raw': 'error code: 524', 'provider_name': 'Targon'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m,res)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\main.py:3015\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3012\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3013\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3015\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3016\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3017\u001b[0m     config,\n\u001b[0;32m   3018\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3019\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3021\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3022\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3023\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3024\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3025\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3026\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3027\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3028\u001b[0m ):\n\u001b[0;32m   3029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3030\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\main.py:2642\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2641\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2642\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2643\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2644\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2645\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2646\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2647\u001b[0m ):\n\u001b[0;32m   2648\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2649\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2650\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2651\u001b[0m     )\n\u001b[0;32m   2652\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     run_with_retry(\n\u001b[0;32m    163\u001b[0m         t,\n\u001b[0;32m    164\u001b[0m         retry_policy,\n\u001b[0;32m    165\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    166\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[0;32m    167\u001b[0m                 _call,\n\u001b[0;32m    168\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[0;32m    169\u001b[0m                 retry_policy\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[0;32m    170\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[0;32m    171\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[0;32m    172\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m    173\u001b[0m             ),\n\u001b[0;32m    174\u001b[0m         },\n\u001b[0;32m    175\u001b[0m     )\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[72], line 12\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#     final_message=state['message']\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minvoke(final_message)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:383\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    379\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    380\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    384\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    385\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    386\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    387\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    388\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    389\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    390\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    391\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    392\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    393\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:1006\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1004\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1005\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:825\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    824\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 825\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    826\u001b[0m                 m,\n\u001b[0;32m    827\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    828\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    829\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    830\u001b[0m             )\n\u001b[0;32m    831\u001b[0m         )\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\language_models\\chat_models.py:1072\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1072\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1073\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1074\u001b[0m     )\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1076\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1178\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1177\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m-> 1178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:1236\u001b[0m, in \u001b[0;36mBaseChatOpenAI._create_chat_result\u001b[1;34m(self, response, generation_info)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;66;03m# Sometimes the AI Model calling will get error, we should raise it (this is\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;66;03m# typically followed by a null value for `choices`, which we raise for\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;66;03m# separately below).\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(response_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;66;03m# Raise informative error messages for non-OpenAI chat completions APIs\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;66;03m# that return malformed responses.\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: {'message': 'Provider returned error', 'code': 524, 'metadata': {'raw': 'error code: 524', 'provider_name': 'Targon'}}",
      "\u001b[0mDuring task with name 'main' and id '4d0a77db-4625-d544-19d7-4e29ffa07887'"
     ]
    }
   ],
   "source": [
    "res=app.invoke({'message':'','code':''})\n",
    "print('f',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa78263",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[HumanMessage(content='', additional_kwargs={}, response_metadata={}, id='3f30e2f0-1b80-4628-a751-ecfe08cb0b60'), AIMessage(content='```python\\nprint(\"Hello, World!\")\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 36, 'total_tokens': 47, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek/deepseek-chat-v3-0324:free', 'system_fingerprint': None, 'id': 'gen-1754927618-oAPK1GAUwSwLWNeMM5HU', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--44145907-943c-4cb4-bf61-a3c78052531e-0', usage_metadata={'input_tokens': 36, 'output_tokens': 11, 'total_tokens': 47, 'input_token_details': {}, 'output_token_details': {}})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef0643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Hello, World!\")'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val=res[1].content\n",
    "val=val.replace('\\n','')\n",
    "val=val.strip('`')\n",
    "val=val[6:]\n",
    "val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
