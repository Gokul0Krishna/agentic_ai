{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107094f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\protein.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632cd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(df:pd.DataFrame):\n",
    "    a=df.isna().sum()\n",
    "    if a.sum()==0:\n",
    "        return a.abs()\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e205131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(df:pd.DataFrame):\n",
    "    'replaces null values with mean of other values'\n",
    "    for i in df.columns:\n",
    "        if (df[i].isna().sum()>0):\n",
    "            grouped = df.groupby([i])\n",
    "            df[i] = grouped[i].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f967428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_null(df:pd.DataFrame):\n",
    "    if (df.isna().sum()).sum()/df.count()[0]>0.1:\n",
    "        return replace(df=df)\n",
    "    else:\n",
    "        return df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discribe_df(df:pd.DataFrame):\n",
    "    \"returns df's discription and correlation\"\n",
    "    x = df.corr()\n",
    "    y = df.info()\n",
    "    return x.iloc[:,-1],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df:pd.DataFrame):\n",
    "    'returns normalized data split into test train split'\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import ConversationChain\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict,Annotated,Sequence\n",
    "from langchain_core.messages import BaseMessage,ToolMessage,SystemMessage,HumanMessage,AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class Agent_converse(TypedDict):\n",
    "    message : Annotated[Sequence[BaseMessage], add_messages]\n",
    "    pathfile : str\n",
    "\n",
    "class Agent_summerize(TypedDict):\n",
    "    content : str\n",
    "\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "def process(state: Agent_converse) -> Agent_converse:\n",
    "    'enter the task/date'\n",
    "    system_prompt = SystemMessage(content=f\"\"\"\n",
    "    \n",
    "    \"\"\")\n",
    "    \n",
    "    user_input = state['message']\n",
    "    final_messages = [system_prompt, user_input]\n",
    "    \n",
    "    response = model.invoke(final_messages)  # no `input=...`\n",
    "    \n",
    "    print(\"Full Response:\", )\n",
    "    if isinstance(response, AIMessage):\n",
    "        print(\"AI says:\", response.content)\n",
    "        return {\"message\": [response]}\n",
    "    else:\n",
    "        print(\"Unexpected response type:\", type(response))\n",
    "        return {\"message\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717cc57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\"SimpleMemory\" object has no field \"buffer\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m llm \u001b[38;5;241m=\u001b[39m Ollama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Add memory so chatbot remembers previous turns\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m memory \u001b[38;5;241m=\u001b[39m SimpleMemory()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Create chatbot chain\u001b[39;00m\n\u001b[0;32m     12\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m ConversationChain(\n\u001b[0;32m     13\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     14\u001b[0m     memory\u001b[38;5;241m=\u001b[39mmemory,\n\u001b[0;32m     15\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# logs prompts and responses\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\OneDrive\\Desktop\\code\\agentic ai\\MCP\\csv_sanity_checker\\chat_memory.py:6\u001b[0m, in \u001b[0;36mSimpleMemory.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []      \u001b[38;5;66;03m# stores conversation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\main.py:997\u001b[0m, in \u001b[0;36mBaseModel.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    995\u001b[0m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;66;03m# if None is returned from _setattr_handler, the attribute was set directly\u001b[39;00m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (setattr_handler \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setattr_handler(name, value)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    998\u001b[0m     setattr_handler(\u001b[38;5;28mself\u001b[39m, name, value)  \u001b[38;5;66;03m# call here to not memo on possibly unknown fields\u001b[39;00m\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_setattr_handlers__[name] \u001b[38;5;241m=\u001b[39m setattr_handler\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydantic\\main.py:1044\u001b[0m, in \u001b[0;36mBaseModel._setattr_handler\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_fields__:\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextra\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;66;03m# TODO - matching error\u001b[39;00m\n\u001b[1;32m-> 1044\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m object has no field \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1046\u001b[0m         \u001b[38;5;66;03m# attribute does not exist, so put it in extra\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_extra__[name] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: \"SimpleMemory\" object has no field \"buffer\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Agent_converse(TypedDict):\n",
    "    message : Annotated[Sequence[BaseMessage], add_messages]\n",
    "    pathfile : str\n",
    "\n",
    "class Agent_summerize(TypedDict):\n",
    "    content : str\n",
    "\n",
    "# Load Ollama model (llama3.2 in this case)\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Interactive loop\n",
    "print(\"ðŸ¤– Chatbot ready! Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "        \n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    \n",
    "    if 'analyse' in user_input.lower():\n",
    "        tool_response = Exploratory_analysis(memory.file_path)\n",
    "        response = chatbot.run(f'summerize this data {tool_response}')\n",
    "        print(\"AI\", response)\n",
    "    \n",
    "    if user_input.lower().startswith(\"set file path\"):\n",
    "        path = user_input.split(\"set file path\", 1)[1].strip()\n",
    "        memory.save_file_path(path)\n",
    "        print(f\"âœ… File path stored: {memory.file_path}\")\n",
    "    else:\n",
    "        # Otherwise, normal chatbot response\n",
    "        response = chatbot.run(user_input)\n",
    "        print(\"Bot:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
