{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107094f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\protein.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632cd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(df:pd.DataFrame):\n",
    "    a=df.isna().sum()\n",
    "    if a.sum()==0:\n",
    "        return a.abs()\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e205131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(df:pd.DataFrame):\n",
    "    'replaces null values with mean of other values'\n",
    "    for i in df.columns:\n",
    "        if (df[i].isna().sum()>0):\n",
    "            grouped = df.groupby([i])\n",
    "            df[i] = grouped[i].transform(lambda x: x.fillna(x.mean()))\n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_null(df:pd.DataFrame):\n",
    "    if (df.isna().sum()).sum()/df.count()[0]>0.1:\n",
    "        return replace(df=df)\n",
    "    else:\n",
    "        return df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discribe_df(df:pd.DataFrame):\n",
    "    \"returns df's discription and correlation\"\n",
    "    x = df.corr()\n",
    "    y = df.info()\n",
    "    return x.iloc[:,-1],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df:pd.DataFrame):\n",
    "    'returns normalized data split into test train split'\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594b716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Chatbot with file_path memory ready! Type 'exit' to quit.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45730 entries, 0 to 45729\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RMSD    45730 non-null  float64\n",
      " 1   F1      45730 non-null  float64\n",
      " 2   F2      45730 non-null  float64\n",
      " 3   F3      45730 non-null  float64\n",
      " 4   F4      45730 non-null  float64\n",
      " 5   F5      45730 non-null  float64\n",
      " 6   F6      45730 non-null  float64\n",
      " 7   F7      45730 non-null  float64\n",
      " 8   F8      45730 non-null  int64  \n",
      " 9   F9      45730 non-null  float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 3.5 MB\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[]\n",
      "Human: make a report summerizeing this correlation of dependent on indepandent RMSD    0.062830\n",
      "F1     -0.898240\n",
      "F2     -0.786188\n",
      "F3     -0.069039\n",
      "F4     -0.891766\n",
      "F5     -0.897765\n",
      "F6     -0.881973\n",
      "F7     -0.521148\n",
      "F8     -0.637287\n",
      "F9      1.000000\n",
      "Name: F9, dtype: float64,information about the tableNone,shape of table(45730, 10)\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "âœ… File path stored: It seems like you've provided a summary of some correlation data between independent variables and their corresponding dependent variables, which are measured using Root Mean Square Deviation (RMSD), F1, F2, F3, F4, F5, F6, and F7. The values range from -0.521148 to 1.000000.\n",
      "\n",
      "However, I do notice that the value for F9 is significantly different from the others. Since RMSD measures the average magnitude of the differences between the observed and predicted values, it's unusual to see an RMSD of 1.000000, which would indicate a perfect fit. \n",
      "\n",
      "Can you tell me more about what this data represents? Is it from a specific experiment or dataset?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from sever import Exploratory_analysis   # make sure it's server.py, not \"sever.py\"\n",
    "\n",
    "# Load Ollama model\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Custom memory with file_path support\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Create chatbot\n",
    "chatbot = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ðŸ¤– Chatbot with file_path memory ready! Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    # If user mentions setting a file path\n",
    "    if user_input.lower().startswith(\"set file path\"):\n",
    "        path = user_input.split(\"set file path\",1)[1].strip()\n",
    "        memory.save_file_path(path)\n",
    "        print(f\"âœ… File path stored: {memory.file_path}\")\n",
    "\n",
    "    if 'analysis' in user_input.lower():\n",
    "        value = f'make a report summerizeing this {Exploratory_analysis(file_path=r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\code\\datasets\\protein.csv\")}'\n",
    "        response = chatbot.run(value)\n",
    "        print(f\"âœ… File path stored: {response}\")\n",
    "    \n",
    "\n",
    "    else:\n",
    "        response = chatbot.run(user_input)\n",
    "        print(\"Bot:\", response)\n",
    "\n",
    "        # You can also access stored file_path any time\n",
    "        print(\"ðŸ“‚ Current file path:\", memory.file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
